{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import cv2\n",
    "import sys\n",
    "import numpy as np\n",
    "import os\n",
    "import inspect\n",
    "from skimage import io\n",
    "from scipy import misc\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "from IPython.display import clear_output\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SSD: Single Shot MultiBox Detector\n",
    "[Ссылка на arxiv \"SSD: Single Shot MultiBox Detector\"](https://arxiv.org/pdf/1512.02325.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 256\n",
    "faces_in_image_limit = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_faces(img):\n",
    "    \"\"\"This function extracts a face from a photo.\n",
    "    \n",
    "    :param img: the image from which we wanna to derive a face.\n",
    "    \n",
    "    :return: np.array of an extracted face and confidence that it is a human face.\n",
    "    \"\"\"\n",
    "    model_file = \"utils/opencv_face_detector_uint8.pb\"\n",
    "    config_file = \"utils/opencv_face_detector.pbtxt\"\n",
    "    \n",
    "    # This network has been created for the Caffe and Tensorflow, I used the second one\n",
    "    net = cv2.dnn.readNetFromTensorflow(model_file, config_file)\n",
    "    \n",
    "    # Returning results\n",
    "    image_data_fin = []\n",
    "    confidence_res = None\n",
    "    \n",
    "    h, w = img.shape[:2]\n",
    "    \n",
    "    # https://www.pyimagesearch.com/2017/11/06/deep-learning-opencvs-blobfromimage-works/ blob description\n",
    "    # First we resize the image to 300x300 according to the pretrained weights\n",
    "    # Second, the scale factor (standard deviation in the z-scoring), I do not use the scale therefore set it as 1.0\n",
    "    # Third, mean-tupple of RGB [mu-Red, mu-Green, mu-Blue] \n",
    "    # Forth, indicates that swap first and last channels in 3-channel image is necessary.\n",
    "    # Fifth, indicates whether image will be cropped after resize or not\n",
    "    blob = cv2.dnn.blobFromImage(cv2.resize(img, (300, 300)), 1.0, (300, 300), [104, 117, 123], False, False)\n",
    "    \n",
    "    # pass the blob through the network and obtain the detections and predictions\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "    \n",
    "    # loop over the detections\n",
    "    for i in range(detections.shape[2]):\n",
    "        # extract the confidence (i.e., probability) associated with the prediction\n",
    "        # https://docs.opencv.org/trunk/d3/d63/classcv_1_1Mat.html\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        # If confidence is higher than 50% than \n",
    "        if confidence > 0.5:\n",
    "            # compute the (x, y)-coordinates of the bounding box for the object\n",
    "            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "            (x, y, x1, y1) = box.astype(\"int\")\n",
    "            # create a new image (augmented image, in the way to cut off everything except a face)\n",
    "            roi_color = img[y:y1, x:x1]\n",
    "            im = resize(roi_color, (img_size, img_size))\n",
    "            image_data_fin.append(im)\n",
    "            confidence_res = confidence\n",
    "    \n",
    "    # If the only one face on a photo then return it (as np.array) and confidence that it is a human face.\n",
    "    if len(image_data_fin) != faces_in_image_limit:\n",
    "        return [], None\n",
    "    else:\n",
    "        return image_data_fin, confidence_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_progress(total, current, image, like_type, missing_imgs):\n",
    "    \"\"\"This function print progress whereas files are handling.\n",
    "    \n",
    "    :param total: total number of files\n",
    "    :param current: current number of handled files\n",
    "    :param image: an image's name\n",
    "    :param like_type: the folder from where we are handling files\n",
    "    :param missing_imgs: number of files which were missed. It's required in purpose to reflect a percentage properly. \n",
    "    \"\"\"\n",
    "    def progressBar(current, total, missing_imgs, barLength = 20):\n",
    "        \"\"\"Represent a progress bar, like that [--->    ] 50%\n",
    "        \n",
    "        :param total: total number of files\n",
    "        :param current: current number of handled files\n",
    "        :param missing_imgs: number of files which were missed. It's required in purpose to reflect a percentage properly. \n",
    "        :param barLength: required in purpose to show the bar of the same length (default 20 symbols)\n",
    "        \"\"\"\n",
    "        percent = float(current) * 100 / (total - missing_imgs)\n",
    "        arrow   = '-' * int(percent/100 * barLength) + '>'\n",
    "        spaces  = ' ' * (barLength - len(arrow))\n",
    "        sys.stdout.write('\\rProgress: [%s%s] %d %%\\n' % (arrow, spaces, percent + 1))\n",
    "        \n",
    "    sys.stdout.write('\\r%d of %d %s files have been handling\\n' % (current, total, like_type))\n",
    "    sys.stdout.write('\\rImage: %s\\n' % image)\n",
    "    progressBar(current, total, missing_imgs)\n",
    "    sys.stdout.flush()\n",
    "\n",
    "def count_files(path):\n",
    "    \"\"\"Count number of files in a folder (missin invisible files, like '.filename')\n",
    "    \n",
    "    :param path: path to folder.\n",
    "    :return: Evaluated number of files\n",
    "    \"\"\"\n",
    "    return len([name for name in path if not name[0] ==\".\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# For each image, we want to know if each picture is attractive or unattractive\n",
    "\n",
    "# list of images translated into np-array\n",
    "images = []\n",
    "# labels to each image\n",
    "labels = []\n",
    "\n",
    "def handle_images(name=''):\n",
    "    \"\"\"The function process all photos and prepares them for training.\n",
    "    \n",
    "    :param name: the name of an user of a folder (name1_like)\n",
    "    \"\"\"\n",
    "    # The directory where this file is placed\n",
    "    currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "    # Path to the folder with all samples folder\n",
    "    data_path = os.path.dirname(currentdir) + '\\\\samples'\n",
    "    \n",
    "    name = name + '_' if name != '' else ''\n",
    "    \n",
    "    # List of files in like/dislike directory\n",
    "    dislikes_images_stack = os.listdir(os.path.join(data_path, name + 'dislike'))\n",
    "    likes_images_stack = os.listdir(os.path.join(data_path, name + 'like'))\n",
    "\n",
    "    def process_folder(images_stack, like_type, name=''):\n",
    "        \"\"\"The function which processes a folder, by handling images an labeling them.\n",
    "        \n",
    "        :param images_stack: a list of images\n",
    "        :param like_type: the type of folder which is processing.\n",
    "        :param name: the name beside the like-type in folder name.\n",
    "        :return: confidence-list (confidence that each passed image is a human face) , number of missed images, \n",
    "        files processed, total number of images\n",
    "        \"\"\"\n",
    "        number_of_images = count_files(images_stack)\n",
    "        files_processed = 0\n",
    "        confidence_list = []\n",
    "        number_of_missing_images = 0\n",
    "\n",
    "        for img in images_stack:\n",
    "            if not img.startswith('.'):\n",
    "                # Print progress\n",
    "                clear_output(wait=True)\n",
    "                print_progress(number_of_images, files_processed, img, like_type, number_of_missing_images)\n",
    "                try:\n",
    "                    # obtain a face \n",
    "                    faces, confidence = extract_faces(cv2.imread(os.path.join(data_path, os.path.join(name + like_type, img))))\n",
    "                except Exception as e:\n",
    "                    raise e\n",
    "                \n",
    "                # Check if the only one face has been retrieved\n",
    "                if len(faces) > 0 and len(faces) < 2:\n",
    "                    confidence_list.append(confidence)\n",
    "                elif len(faces) == 0:\n",
    "                    number_of_missing_images += 1\n",
    "                \n",
    "                # Labeling\n",
    "                for face in faces:\n",
    "                    images.append(face)\n",
    "                    if like_type == 'like':\n",
    "                        labels.append(1)\n",
    "                    else:\n",
    "                        labels.append(0)\n",
    "                    files_processed += 1\n",
    "        return confidence_list, number_of_missing_images, files_processed, number_of_images\n",
    "\n",
    "    # Gather infromation regard the processed files (along with processing)\n",
    "    conf_list, NoMI, proc_files, NoI = process_folder(dislikes_images_stack, 'dislike', name)\n",
    "    conf_list2, NoMI2, proc_files2, NoI2 = process_folder(likes_images_stack, 'like', name)\n",
    "    conf_list.extend(conf_list2)\n",
    "    conf_list = np.array(conf_list)\n",
    "    NoMI += NoMI2\n",
    "    NoI += NoI2\n",
    "    return {'face_convincing': pd.DataFrame([['{:.2f} %'.format(np.mean(conf_list) * 100)], ['{:.2f} %'.format(np.amax(conf_list) * 100)], ['{:.2f} %'.format(np.amin(conf_list) * 100)], ['{:.2f} %'.format(np.std(conf_list) * 100)]], index=['mean', 'max', 'min', 'std'], columns=['percents']), 'images': pd.DataFrame([[NoI], [NoMI], ['{:.2f} %'.format((NoI - NoMI2)/NoI * 100)], [proc_files2], [proc_files]], index=['toatal amount', 'missed amount', 'handled ratio', 'handled likes', 'handled dislikes'], columns=['data'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1295 of 1350 like files have been handling\n",
      "\r",
      "Image: 640x800_ffe1f99f-4dea-47bf-b616-a94668d6b879.jpg\n",
      "\r",
      "Progress: [------------------->] 100 %\n"
     ]
    }
   ],
   "source": [
    "recap = handle_images('milka')\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>toatal amount</th>\n",
       "      <td>3011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missed amount</th>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>handled ratio</th>\n",
       "      <td>98.21 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>handled likes</th>\n",
       "      <td>1296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>handled dislikes</th>\n",
       "      <td>1519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     data\n",
       "toatal amount        3011\n",
       "missed amount         196\n",
       "handled ratio     98.21 %\n",
       "handled likes        1296\n",
       "handled dislikes     1519"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# images -- shows the information about handled photos\n",
    "# face_convincing -- shows statistics about face retrieving\n",
    "recap['images']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2815, 256, 256, 3)\n",
      "(2815,)\n"
     ]
    }
   ],
   "source": [
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

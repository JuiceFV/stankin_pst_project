{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Импорт пакетов\n",
    "- **opencv** - пакет для Computer Vision и дата препроцессинага для него.\n",
    "- **sys** - пакет для работы с выводом на консоль.\n",
    "- **numpy** - пакет для работы с массивами данных.\n",
    "- **os** - пакет для работы с операционной системой, используется в связке с sys.\n",
    "- **inspect** - пакет помогает извлекать информацию из лайвв объектов, таких как классы, функции и т.т.п.\n",
    "- **skimage** - пакет алгоритмов, предназначенных для работы с изображениями, в особенности с их препроцессингом. Дополнение к opencv. От сюда извлекаем модуль ***io*** (Утилиты для чтения и записи изображений в различных форматаx) и функцию ***resize*** (Изменяет размер изображения до указанного).\n",
    "- **matplotlib.pyplot** - модуль для графического отображения данных.\n",
    "- **IPython** - от сюда извлекается функция, которая помогает очищать вывод в jupyter.\n",
    "- **pandas** - пакет для обработки и анализа данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import cv2\n",
    "import sys\n",
    "import numpy as np\n",
    "import os\n",
    "import inspect\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "from IPython.display import clear_output\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Глобальные переменные\n",
    "1. **img_size** - размер изображения, на выходе. Данный размер должен совпадать с размером изображений на котых обучается наша CNN.\n",
    "2. **faces_in_image_limit** - количество лиц, на одной фотографии. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 256\n",
    "faces_in_image_limit = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Основной алгоритм. SSD: Single Shot MultiBox Detector\n",
    "\n",
    "Выбор пал на SSD, т.к. по сравнению с Haar Cascade данный алгоритм работает в разы лучше. В дополнение он быстрее Faster R-CNN, а перформансы у них очень близки друг к другу. Сравнение алгоритмов можно найти [тут](https://towardsdatascience.com/face-detection-models-which-to-use-and-why-d263e82c302c). Полное описание SSD от их авторов можно найти на [arxiv'e](https://arxiv.org/pdf/1512.02325.pdf) наглядное описание можно посмотреть [тут](https://pythonawesome.com/ssd-single-shot-multibox-detector-a-pytorch-tutorial-to-object-detection/).\n",
    "\n",
    "## Основная логика\n",
    "\n",
    "На вход поступает N 3-х канальных RGB картинок $X^T \\in \\mathbb{R}^N$, где $x^T = (w, h, 3)$. В зависимости от типа SSD нужно масшатабировать картинку, чтобы она была пригодна для input-layer. В нашем случае $x^T = (300, 300, 3)$. Далее каждая картинка прогоняется через свёрточные слои. Авторы использовали немного модифицированную VGG16.\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&\\tilde{x}_1 \\sim MaxPool_1(Conv_{1_2}(Conv_{1_1}(x)))\\\\\n",
    "&\\tilde{x}_2 \\sim MaxPool_2(Conv_{2_2}(Conv_{2_1}(\\tilde{x}_1)))\\\\\n",
    "&\\tilde{x}_3 \\sim MaxPool_3(Conv_{3_3}(Conv_{3_2}(Conv_{3_1}(\\tilde{x}_2))))\\\\\n",
    "&\\tilde{x}_4 \\sim MaxPool_4(Conv_{4_3}(Conv_{4_2}(Conv_{4_1}(\\tilde{x}_3))))\\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "Здесь, приметим, что $\\tilde{x}_4^T \\in \\mathbb{R}^{38 \\times 38 \\times 512}$.\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&\\tilde{x}_5 \\sim MaxPool_5(Conv_{5_3}(Conv_{5_2}(Conv_{5_1}(\\tilde{x}_4))))\\\\\n",
    "&\\tilde{x}_6 \\sim Conv_{6}(\\tilde{x}_5)\\\\\n",
    "&\\tilde{x}_7 \\sim Conv_{7}(\\tilde{x}_6)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Таким образом мы сможем извлечь даже мелкие детали. На данный момент $\\tilde{x}_7^T \\in \\mathbb{R}^{19 \\times 19 \\times 1024}$.\n",
    "Далее на топ архитектуры добавляются вспомогательные слои:\n",
    "\n",
    "$$\n",
    "\\tilde{x}_7^T \\in \\mathbb{R}^{19 \\times 19 \\times 1024} \\rightarrow \\underbrace{Conv_{8_2}(Conv_{8_1}(\\tilde{x}_7))}_{\\tilde{x}_8^T \\in \\mathbb{R}^{10 \\times 10 \\times 512}} \\rightarrow \\underbrace{Conv_{9_2}(Conv_{9_1}(\\tilde{x}_8))}_{\\tilde{x}_9^T \\in \\mathbb{R}^{5 \\times 5 \\times 256}} \\rightarrow \\underbrace{Conv_{10_2}(Conv_{10_1}(\\tilde{x}_9))}_{\\tilde{x}_{10}^T \\in \\mathbb{R}^{3 \\times 3 \\times 256}} \\rightarrow \\underbrace{Conv_{11_2}(Conv_{11_1}(\\tilde{x}_{10}))}_{\\tilde{x}_{11}^T \\in \\mathbb{R}^{1 \\times 1 \\times 256}}\n",
    "$$\n",
    "\n",
    "У нас есть 6 помеченных слоёв, на которых мы будем проводить детекцию с разным уровнем детализации. Теперь на свёрнутую картинку накладываются дефолтные [AnchorBoxes](https://www.mathworks.com/help/vision/ug/anchor-boxes-for-object-detection.html) (Приоры):\n",
    "\n",
    "* **Приоры накладываются на помеченные карты характеристик $x$**.\n",
    "* **Каждый приор имеет масштаб $s$, тогда площадь данного приора равна площади квадрата со стороной $\\sqrt{s}$**. Например для самой большой карты характеристик (КХ) $\\tilde{x}_4$ масштаб приора будет 10\\% от размерности изображения. Для следующей КХ ($\\tilde{x}_7$) 20\\%, для следующей 30\\% и так до 90\\%.\n",
    "* **В каждой ячейке карты характеристик, находятся несколько приор с разным соотношением сторон**. Все КХ будут иметь приоры с соотношением сторон $\\frac{1}{1},\\ \\frac{1}{2},\\ \\frac{2}{1}$. Промежуточные КХ ($\\tilde{x}_7,\\ \\tilde{x}_8,\\ \\tilde{x}_9$) в дополнение имеют $\\frac{1}{3},\\ \\frac{3}{2}$ приоры. И напоследок, каждая КХ имеет дополнительный приор $\\frac{1}{1}$.\n",
    "\n",
    "\n",
    "\n",
    "| Карта характеристик |   Размерность  | Масштаб приора |                                  Соотношения сторон                                 | Количество приор на одну ячейку | Общее количество приор на КХ |\n",
    "|:-------------------:|:--------------:|:--------------:|:-----------------------------------------------------------------------------------:|:-------------------------------:|:----------------------------:|\n",
    "|    $\\tilde{x}_4$    | $38 \\times 38$ |       0.1      |               $\\frac{1}{1};\\ \\frac{1}{2};\\ \\frac{2}{1};$ + доп. приор               |                4                |             5766             |\n",
    "|    $\\tilde{x}_7$    | $19 \\times 19$ |       0.2      |               $\\frac{1}{1};\\ \\frac{1}{2};\\ \\frac{2}{1};$ + доп. приор               |                6                |             2166             |\n",
    "|    $\\tilde{x}_8$    | $10 \\times 10$ |      0.375     | $\\frac{1}{1};\\ \\frac{1}{2};\\ \\frac{2}{1};\\ \\frac{1}{3};\\ \\frac{3}{2};$ + доп. приор |                6                |              600             |\n",
    "|    $\\tilde{x}_9$    |  $5 \\times 5$  |      0.55      | $\\frac{1}{1};\\ \\frac{1}{2};\\ \\frac{2}{1};\\ \\frac{1}{3};\\ \\frac{3}{2};$ + доп. приор |                6                |              150             |\n",
    "|   $\\tilde{x}_{10}$  |  $3 \\times 3$  |      0.725     |               $\\frac{1}{1};\\ \\frac{1}{2};\\ \\frac{2}{1};$ + доп. приор               |                4                |              36              |\n",
    "|   $\\tilde{x}_{11}$  |  $1 \\times 1$  |       0.9      |               $\\frac{1}{1};\\ \\frac{1}{2};\\ \\frac{2}{1};$ + доп. приор               |                4                |               4              |\n",
    "|   **Общее количество**  |        -       |        -       |                                          -                                          |                -                |          **8732 приора**         |\n",
    "\n",
    "Приоры объявлены с помощью масштабирующего фактора и соотношения сторон\n",
    "\n",
    "1. Со следующими, масштобирующем фактором и соотношением сторон:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&w \\cdot h = s^2\n",
    "\\\\\n",
    "&\\frac{w}{h} = a\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "2. От сюда получаем:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&w = s \\cdot \\sqrt{a}\n",
    "\\\\\n",
    "&h = \\frac{s}{\\sqrt{a}}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Для каждого приора расчитывается вероятность (confidence) для каждого объекта. В нашем случае только лицо, т.е. какова вероятность, что в пределах приора находится лицо. Далее мы пытаемся отрегулировать данный приор таким образом, чтобы данная вероятность была максимальной. Тем самым мы получаем следующие сдвиги.\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&g_{{c}_{x}} = \\frac{c_x - \\hat{с}_x}{\\hat{w}}\n",
    "\\\\\n",
    "&g_{{c}_{y}} = \\frac{c_y - \\hat{с}_y}{\\hat{h}}\n",
    "\\\\\n",
    "&g_w = \\log{\\left(\\frac{w}{\\hat{w}}\\right)}\n",
    "\\\\\n",
    "&g_h = \\log{\\left(\\frac{h}{\\hat{h}}\\right)}\n",
    "\\end{aligned}\n",
    "$$\n",
    "где $(c_x, c_y, w, h)$ данные приора с наибольшей вероятностю содержания объекта.\n",
    "\n",
    "Как видите, каждое смещение нормализовано на соответствующий размер приора. Что логично, потому что определенное смещение будет менее значительным для более крупного приора, чем для меньшего.\n",
    "\n",
    "Чтобы определить саму область используется IoU (Intersection over Unioin) $\\frac{A \\cap B}{A \\cup B}$. Если IoU приора и реального AnchorBox'a больше 0.5 это значит совпадение, иначе несовпадение.\n",
    "\n",
    "Для обучения используются следующие лоссы:\n",
    "\n",
    "1. Позиция:\n",
    "\n",
    "$$\n",
    "L_{loc}(x, l, g) = \\sum_{i \\in Pos}^N{\\sum_{m \\in \\{c_x, c_y, w, h\\}}{\\mathbb{1}\\{IoU(x_{ij}^k) > 0.5\\}\\text{L1}(l_i^m - \\hat{g}_j^m})}\n",
    "$$\n",
    "\n",
    "2. Вероятности:\n",
    "\n",
    "$$\n",
    "L_{conf}(x,c) = - \\sum_{i \\in Pos}^N{\\mathbb{1}\\{IoU(x_{ij}^p) > 0.5\\}\\log{(\\hat{c}_i^p)}} - \\sum_{i \\in N \\in g}{\\log{(\\hat{c}_i^0)}}, \\qquad \\text{где }\\hat{c}_i^p = \\frac{e^{c_j^p}}{\\sum_p{c_j^p}} \n",
    "$$\n",
    "\n",
    "3. Общая:\n",
    "\n",
    "$$\n",
    "L(x,c,l,g) = \\frac{1}{N}(L_{conf}(x,c) + \\alpha L_{loc}(x,l,g))\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_faces(img):\n",
    "    \"\"\"This function extracts a face from a photo.\n",
    "    \n",
    "    :param img: the image from which we wanna to derive a face.\n",
    "    \n",
    "    :return: np.array of an extracted face and confidence that it is a human face.\n",
    "    \"\"\"\n",
    "    model_file = \"utils/opencv_face_detector_uint8.pb\"\n",
    "    config_file = \"utils/opencv_face_detector.pbtxt\"\n",
    "    \n",
    "    # This network has been created for the Caffe and Tensorflow, I used the second one\n",
    "    net = cv2.dnn.readNetFromTensorflow(model_file, config_file)\n",
    "    \n",
    "    # Returning results\n",
    "    image_data_fin = []\n",
    "    confidence_res = None\n",
    "    \n",
    "    h, w = img.shape[:2]\n",
    "    \n",
    "    # https://www.pyimagesearch.com/2017/11/06/deep-learning-opencvs-blobfromimage-works/ blob description\n",
    "    # First we resize the image to 300x300 according to the pretrained weights\n",
    "    # Second, the scale factor (standard deviation in the z-scoring), I do not use the scale therefore set it as 1.0\n",
    "    # Third, mean-tupple of RGB [mu-Red, mu-Green, mu-Blue] \n",
    "    # Forth, indicates that swap first and last channels in 3-channel image is necessary.\n",
    "    # Fifth, indicates whether image will be cropped after resize or not\n",
    "    blob = cv2.dnn.blobFromImage(cv2.resize(img, (300, 300)), 1.0, (300, 300), [104, 117, 123], False, False)\n",
    "    \n",
    "    # pass the blob through the network and obtain the detections and predictions\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "    \n",
    "    # loop over the detections\n",
    "    for i in range(detections.shape[2]):\n",
    "        # extract the confidence (i.e., probability) associated with the prediction\n",
    "        # https://docs.opencv.org/trunk/d3/d63/classcv_1_1Mat.html\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        # If confidence is higher than 50% than \n",
    "        if confidence > 0.5:\n",
    "            # compute the (x, y)-coordinates of the bounding box for the object\n",
    "            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "            (x, y, x1, y1) = box.astype(\"int\")\n",
    "            # create a new image (augmented image, in the way to cut off everything except a face)\n",
    "            roi_color = img[y:y1, x:x1]\n",
    "            im = resize(roi_color, (img_size, img_size))\n",
    "            image_data_fin.append(im)\n",
    "            confidence_res = confidence\n",
    "    \n",
    "    # If the only one face on a photo then return it (as np.array) and confidence that it is a human face.\n",
    "    if len(image_data_fin) != faces_in_image_limit:\n",
    "        return [], None\n",
    "    else:\n",
    "        return image_data_fin, confidence_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Дополнительные функции\n",
    "\n",
    "- **print_progress** - рисует прогресбар вида [--->    ] 50%.\n",
    "- **count_files** - считает количество файлов в директории."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_progress(total, current, image, like_type, missing_imgs):\n",
    "    \"\"\"This function print progress whereas files are handling.\n",
    "    \n",
    "    :param total: total number of files\n",
    "    :param current: current number of handled files\n",
    "    :param image: an image's name\n",
    "    :param like_type: the folder from where we are handling files\n",
    "    :param missing_imgs: number of files which were missed. It's required in purpose to reflect a percentage properly. \n",
    "    \"\"\"\n",
    "    def progressBar(current, total, missing_imgs, barLength = 20):\n",
    "        \"\"\"Represent a progress bar, like that [--->    ] 50%\n",
    "        \n",
    "        :param total: total number of files\n",
    "        :param current: current number of handled files\n",
    "        :param missing_imgs: number of files which were missed. It's required in purpose to reflect a percentage properly. \n",
    "        :param barLength: required in purpose to show the bar of the same length (default 20 symbols)\n",
    "        \"\"\"\n",
    "        percent = float(current) * 100 / (total - missing_imgs)\n",
    "        arrow   = '-' * int(percent/100 * barLength) + '>'\n",
    "        spaces  = ' ' * (barLength - len(arrow))\n",
    "        sys.stdout.write('\\rProgress: [%s%s] %d %%\\n' % (arrow, spaces, percent + 1))\n",
    "        \n",
    "    sys.stdout.write('\\r%d of %d %s files have been handling\\n' % (current, total, like_type))\n",
    "    sys.stdout.write('\\rImage: %s\\n' % image)\n",
    "    progressBar(current, total, missing_imgs)\n",
    "    sys.stdout.flush()\n",
    "\n",
    "def count_files(path):\n",
    "    \"\"\"Count number of files in a folder (missin invisible files, like '.filename')\n",
    "    \n",
    "    :param path: path to folder.\n",
    "    :return: Evaluated number of files\n",
    "    \"\"\"\n",
    "    return len([name for name in path if not name[0] ==\".\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обрабатывающая функция\n",
    "\n",
    "Основная функция, которая обрбатывает фотографии, извлекая из них лица. Итогом она возвращает небольшую статистику по обработанным фотографиям:\n",
    "\n",
    "- **toatal amount** - сколько фотографий обработанно всего.\n",
    "- **missed amount** - количество пропущенных фотографий (из которых не получилось извлечь лица)\n",
    "- **handled ratio** - процент успешно обработанных фотографий.\n",
    "- **handled likes** - количество успешно обработанных фотографий из понравившихся.\n",
    "- **handled dislikes** - количество успешно обработанных фотографий из непонравившихся."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# For each image, we want to know if each picture is attractive or unattractive\n",
    "\n",
    "# list of images translated into np-array\n",
    "images = []\n",
    "# labels to each image\n",
    "labels = []\n",
    "\n",
    "def handle_images(name=''):\n",
    "    \"\"\"The function process all photos and prepares them for training.\n",
    "    \n",
    "    :param name: the name of an user of a folder (name1_like)\n",
    "    \"\"\"\n",
    "    # The directory where this file is placed\n",
    "    currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "    # Path to the folder with all samples folder\n",
    "    data_path = os.path.join(os.path.dirname(currentdir), 'samples')\n",
    "    \n",
    "    name = name + '_' if name != '' else ''\n",
    "    \n",
    "    # List of files in like/dislike directory\n",
    "    dislikes_images_stack = os.listdir(os.path.join(data_path, name + 'dislike'))\n",
    "    likes_images_stack = os.listdir(os.path.join(data_path, name + 'like'))\n",
    "\n",
    "    def process_folder(images_stack, like_type, name=''):\n",
    "        \"\"\"The function which processes a folder, by handling images an labeling them.\n",
    "        \n",
    "        :param images_stack: a list of images\n",
    "        :param like_type: the type of folder which is processing.\n",
    "        :param name: the name beside the like-type in folder name.\n",
    "        :return: confidence-list (confidence that each passed image is a human face) , number of missed images, \n",
    "        files processed, total number of images\n",
    "        \"\"\"\n",
    "        number_of_images = count_files(images_stack)\n",
    "        files_processed = 0\n",
    "        confidence_list = []\n",
    "        number_of_missing_images = 0\n",
    "\n",
    "        for img in images_stack:\n",
    "            if not img.startswith('.'):\n",
    "                # Print progress\n",
    "                clear_output(wait=True)\n",
    "                print_progress(number_of_images, files_processed, img, like_type, number_of_missing_images)\n",
    "                try:\n",
    "                    # obtain a face \n",
    "                    faces, confidence = extract_faces(cv2.imread(os.path.join(data_path, os.path.join(name + like_type, img))))\n",
    "                except Exception as e:\n",
    "                    raise e\n",
    "                \n",
    "                # Check if the only one face has been retrieved\n",
    "                if len(faces) > 0 and len(faces) < 2:\n",
    "                    confidence_list.append(confidence)\n",
    "                elif len(faces) == 0:\n",
    "                    number_of_missing_images += 1\n",
    "                \n",
    "                # Labeling\n",
    "                for face in faces:\n",
    "                    images.append(face)\n",
    "                    if like_type == 'like':\n",
    "                        labels.append(1)\n",
    "                    else:\n",
    "                        labels.append(0)\n",
    "                    files_processed += 1\n",
    "        return confidence_list, number_of_missing_images, files_processed, number_of_images\n",
    "\n",
    "    # Gather infromation regard the processed files (along with processing)\n",
    "    conf_list, NoMI, proc_files, NoI = process_folder(dislikes_images_stack, 'dislike', name)\n",
    "    conf_list2, NoMI2, proc_files2, NoI2 = process_folder(likes_images_stack, 'like', name)\n",
    "    conf_list.extend(conf_list2)\n",
    "    conf_list = np.array(conf_list)\n",
    "    NoMI += NoMI2\n",
    "    NoI += NoI2\n",
    "    return {'face_convincing': pd.DataFrame([['{:.2f} %'.format(np.mean(conf_list) * 100)], ['{:.2f} %'.format(np.amax(conf_list) * 100)], ['{:.2f} %'.format(np.amin(conf_list) * 100)], ['{:.2f} %'.format(np.std(conf_list) * 100)]], index=['mean', 'max', 'min', 'std'], columns=['percents']), 'images': pd.DataFrame([[NoI], [NoMI], ['{:.2f} %'.format((NoI - NoMI2)/NoI * 100)], [proc_files2], [proc_files]], index=['toatal amount', 'missed amount', 'handled ratio', 'handled likes', 'handled dislikes'], columns=['data'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "5823 of 7088 like files have been handling\n",
      "\r",
      "Image: wN6xdJXpATibcJrNLFNH8D.jpg\n",
      "\r",
      "Progress: [------------------->] 100 %\n"
     ]
    }
   ],
   "source": [
    "recap = handle_images()\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>toatal amount</th>\n",
       "      <td>10126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missed amount</th>\n",
       "      <td>1887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>handled ratio</th>\n",
       "      <td>87.51 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>handled likes</th>\n",
       "      <td>5823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>handled dislikes</th>\n",
       "      <td>2416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     data\n",
       "toatal amount       10126\n",
       "missed amount        1887\n",
       "handled ratio     87.51 %\n",
       "handled likes        5823\n",
       "handled dislikes     2416"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# images -- shows the information about handled photos\n",
    "# face_convincing -- shows statistics about face retrieving\n",
    "recap['images']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8239, 256, 256, 3)\n",
      "(8239,)\n"
     ]
    }
   ],
   "source": [
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сохранение фотографий на жёстком диске"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving processed_val_images.npy\n",
      "Saving processed_val_labels.npy\n"
     ]
    }
   ],
   "source": [
    "def save_file(data, file_path_name):\n",
    "    \"\"\"Takes all our data here, images and labels. Compresses images in a numpy file. \n",
    "    \n",
    "    :param data: the data we wanna to save\n",
    "    :param file_path_name: path to file where we wanna to store the data\n",
    "    \"\"\"\n",
    "    print(\"Saving {}.npy\".format(file_path_name))\n",
    "    np.save(file_path_name, data)\n",
    "\n",
    "save_file(images, \"processed_val_images\")\n",
    "save_file(labels, \"processed_val_labels\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tinder",
   "language": "python",
   "name": "tinder"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
